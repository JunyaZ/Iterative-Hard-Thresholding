{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection for Categorical Features using Iterative Hard Thresholding\n",
    "\n",
    "Feature selection is a very important task in machine learning tasks. Finding a relevant subset of features improves generalization, robustness to noise, and convergence to targets. A prominent technique in feature selection *Iterative Hard Thresholding (IHT)*. Although IHT is a powerful technique for feature selection, it is not designed for categorical features. In this notebook, I will give a walkthrough on **how to extend IHT to categorical datasets**. For validation, I will compare IHT to other machine learning techniques that also perform feature selections such as LASSO and Random Forest.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Hard Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Consider a dataset $(\\mathbf{X_i}, y_i)$ for $i = [n] = 1,2,3 ... n$, where $\\mathbf{X_i} \\in \\mathbb{R}^m$ and $y_i \\in \\mathbb{R}.$ We seek to find a k-sparse vector $\\mathbf{B} \\in  \\mathbb{R}^m$ with the following objective: \n",
    "\n",
    "\n",
    "$$ \\min_{\\|\\mathbf{B}\\|_0 = k} \\| \\mathbf{y} - f(\\mathbf{X} ;\\mathbf{B}) \\|\n",
    "$$\n",
    "\n",
    "where $\\mathbf{X} \\in \\mathbb{R}^{n \\times m}, \\mathbf{y} \\in  \\mathbb{R}^{n} $ denote the data matrix and the response vector. The $l_0$ norm denotes the number of non-zero elements in $\\mathbf{B}$ and $f$ is a given task-specific function. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Intuitively, learning $\\mathbf{B}$ is equivalent to learning a set of $k$ relevant features that best recover the response vector. Thus, by solving this optimization problem, one can identify relevant features. \n",
    "\n",
    "IHT assumes there exists a linear relationship between a subset of the measured variable and the response vector , and seeks to retain the top-k values of the entire feature vector after each iteration. Let $\\mathbf{B}^0 = \\mathbf{0}$, IHT follows the update rule:\n",
    "\n",
    "$$\n",
    "\\mathbf{B}^{t+1} =  \\mathbf{H}_k(\\mathbf{B}^{t} - \\lambda \\bigtriangledown_{\\mathbf{B}^t} L(f(\\mathbf{X} ;\\mathbf{B}),y))\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import grad\n",
    "import jax.numpy as NP\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used in this work to validate our model was downloaded from [UCL Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Molecular+Biology+(Splice-junction+Gene+Sequences)). The data described Splice-junction Gene Sequences. The Splice junctions are points on a DNA sequence at which 'superfluous' DNA is removed during the process of protein creation in higher organisms.  The problem posed in this dataset is to recognize, given a sequence of DNA, the boundaries between exons (the parts of the DNA sequence retained after splicing) and introns (the parts of the DNA sequence that are spliced out). This problem consists of two subtasks: recognizing exon/intron boundaries (referred to as EI sites), and recognizing intron/exon boundaries (IE sites). (In the biological community, IE borders are referred to a \"acceptors\" while EI borders are referred to as \"donors\".) \n",
    "\n",
    "The data includes 3190 sample with 60 sequential DNA nucleotide positions as features .The data are classfied into 3 classes: EI, IE, and Neither. Each of these fields is almost always filled by one of {A, C, G, T}. Other characters indicate ambiguity among the standard characters according to the following table:\n",
    "\n",
    "\t\t\tcharacter\t    meaning\n",
    "\t\t\t---------\t----------------\n",
    "\t\t\t    D\t\t  A or G or T\n",
    "\t\t\t    N           A or G or C or T\n",
    "\t\t\t    S                C or G\n",
    "\t\t\t    R\t\t     A or G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of data is:  (3190, 60)\n",
      "Show example of dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  0  1  2  3  4  5  6  7  8  9   ... 50 51 52 53 54 55 56 57 58 59\n",
       "0  C  C  A  G  C  T  G  C  A  T  ...  A  G  C  C  A  G  T  C  T  G\n",
       "1  A  G  A  C  C  C  G  C  C  G  ...  G  T  G  C  C  C  C  C  G  C\n",
       "2  G  A  G  G  T  G  A  A  G  G  ...  C  A  C  G  G  G  G  A  T  G\n",
       "3  G  G  G  C  T  G  C  G  T  T  ...  G  G  T  T  T  T  C  C  C  C\n",
       "4  G  C  T  C  A  G  C  C  C  C  ...  C  C  T  T  G  A  C  C  C  T\n",
       "5  C  A  G  A  C  T  G  G  G  T  ...  G  A  G  A  C  C  A  C  A  G\n",
       "6  C  C  T  T  T  G  A  G  G  A  ...  G  T  G  G  C  C  G  C  C  A\n",
       "7  C  C  C  T  C  G  T  G  C  G  ...  G  G  T  C  G  T  G  G  G  G\n",
       "8  T  G  G  C  G  A  C  T  A  C  ...  G  C  T  C  C  A  G  T  C  C\n",
       "9  A  A  G  C  T  G  A  C  A  G  ...  G  A  G  G  G  T  G  A  G  A\n",
       "\n",
       "[10 rows x 60 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafile =\"molecularData.csv\"\n",
    "labelfile= \"molecularLabel.csv\"\n",
    "df=pd.read_csv(datafile,header=None)\n",
    "print(\"The shape of data is: \",df.shape)\n",
    "print(\"Show example of dataset\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " read data into the numpy array format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt(datafile, dtype= str, delimiter = \",\")\n",
    "label= np.genfromtxt(labelfile, dtype = str, delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['EI', 'EI', 'EI', ..., 'N', 'N', 'N'], dtype='<U2')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classes are: ['EI', 'IE', 'N']\n",
      "The number of classes: 3\n"
     ]
    }
   ],
   "source": [
    "uniqueClasses = np.unique(label).tolist()\n",
    "numClasses = len(uniqueClasses)\n",
    "print(\"The classes are:\",uniqueClasses)\n",
    "print(\"The number of classes:\",numClasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encoding Categorical Features\n",
    "One-hot encoding is an extremely common data transformation performed after indexing categorical variables.\n",
    "OneHotEncoder, which will convert each distinct value to a Boolean flag (1 or 0) as a component in a vector。\n",
    "One hot encoding creates new (binary) columns, indicating the presence of each possible value from the original data.\n",
    "In this dataset, features are not given as continuous values but categorical. For example each column could have different possiable features['A', 'C','G', 'T']. We use column 0 as a example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  C\n",
       "1  A\n",
       "2  G\n",
       "3  G\n",
       "4  G\n",
       "5  C\n",
       "6  C\n",
       "7  C\n",
       "8  T\n",
       "9  A"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,0:1].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the possible values in column 0 are: ['C' 'A' 'G' 'T' 'D']\n"
     ]
    }
   ],
   "source": [
    "print(\"All the possible values in column 0 are:\",df[0].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So One hot encoding will creates new (binary) columns, indicating the presence of each possible value from the original data, show as follwing:\n",
    "![image info](./Onehot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now，we run following code to encoding our data, the feature name will show as following and filled by binary data 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Junya/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "OHC = OneHotEncoder().fit(data)\n",
    "OHCL = OneHotEncoder().fit(label.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Setting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classW: The array holds the weight class for each class\n",
    "\n",
    "classWL: The array holds the weights for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classW = class_weight.compute_class_weight('balanced', np.unique(label), label)\n",
    "classWL = np.array([classW[uniqueClasses.index(i)] for i in label]).reshape(-1,1) #Calculate weight class for each sample\n",
    "label = LabelEncoder().fit_transform(label)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, label, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into training set and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "classCount = list(map(len, OHC.categories_)) #Number of all possible values for each categorical feature\n",
    "indices = np.cumsum(classCount) # For indexing between coefficient and categorical features\n",
    "DIM = indices[-1]\n",
    "indices = np.insert(indices,0, 0)\n",
    "X_trainC = OHC.transform(X_train).toarray()\n",
    "X_testC = OHC.transform(X_test).toarray()\n",
    "dataC = OHC.transform(data).toarray()\n",
    "X_current, Y_current, weight =  None, None, None #Placeholder for batch data\n",
    "num_train = X_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I set up the parameter for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 2000\n",
    "lr = 0.1\n",
    "s = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregateFeature(gradients, numSplit):\n",
    "    gradients = gradients.flatten()\n",
    "    sumList = []\n",
    "    current = 0\n",
    "    for i in numSplit:\n",
    "        sumList.append(np.mean(np.abs(gradients[current: current + i ])))\n",
    "        current = current + i\n",
    "    return sumList\n",
    "def thresholding(coeff):\n",
    "    copyCof = coeff[:]\n",
    "    coeff = np.sum(np.abs(np.array(coeff)), axis = 0) \n",
    "    sum_coeff = aggregateFeature(coeff, classCount)\n",
    "    rankingBest = np.argsort(np.abs(sum_coeff)).ravel()[-s:]\n",
    "    if rankingBest.shape[0] < s:\n",
    "        print(\"rankBest less than s features\")\n",
    "    selected = set([i for j in rankingBest for i in range(indices[j], indices[j+1])]) #List of selected coefficient\n",
    "    coeff = coeff.flatten()\n",
    "    notSelected = list(set(range(len(coeff))).difference(selected))\n",
    "    copyCof[:,notSelected] = 0\n",
    "    return copyCof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateBatch():\n",
    "    #int(num_train / 5)\n",
    "    index = np.random.choice(num_train, size =int(num_train / 1), replace =  False)\n",
    "    global X_current\n",
    "    global Y_current\n",
    "    global weight\n",
    "    X_current = X_trainC[index]\n",
    "    Y_current = y_train[index].reshape(-1,1)\n",
    "    weight = classWL[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression(coeff):  # Define the softmax function\n",
    "  y = NP.exp(NP.dot(X_current, coeff.T))\n",
    "  s = NP.expand_dims(NP.sum(y, axis = 1), 1)\n",
    "  y = y / s\n",
    "  Y_currentT = OHCL.transform(Y_current).toarray()\n",
    "  label_logprobs = NP.multiply(NP.log(y) , Y_currentT) #+ NP.multiply(NP.log(1 - y) , (1 - Y_currentT))\n",
    "  label_logprobs = weight * label_logprobs\n",
    "  return -NP.mean(label_logprobs)\n",
    "\n",
    "  \n",
    "def regressionTest(coeff):  # Define a function\n",
    "  y = np.exp(np.dot(X_testC, coeff.T))\n",
    "  s = np.expand_dims(np.sum(y, axis = 1), 1)\n",
    "  y = y / s \n",
    "  return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IHT Model Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error: 0.4223118  | Accuracy: 0.25914315569487983\n",
      "Training error: 0.17073604  | Accuracy: 0.9456635318704284\n",
      "Training error: 0.11760215  | Accuracy: 0.9487983281086729\n",
      "Training error: 0.09478419  | Accuracy: 0.9508881922675027\n",
      "Training error: 0.08186467  | Accuracy: 0.955067920585162\n",
      "Training error: 0.073409416  | Accuracy: 0.9571577847439916\n",
      "Training error: 0.067366384  | Accuracy: 0.9571577847439916\n",
      "Training error: 0.06278567  | Accuracy: 0.9582027168234065\n",
      "Training error: 0.059164897  | Accuracy: 0.9592476489028213\n",
      "Training error: 0.056212064  | Accuracy: 0.9582027168234065\n",
      "Training error: 0.05374511  | Accuracy: 0.9582027168234065\n",
      "Training error: 0.05164423  | Accuracy: 0.9582027168234065\n",
      "Training error: 0.049827036  | Accuracy: 0.9582027168234065\n",
      "Training error: 0.048234776  | Accuracy: 0.9571577847439916\n",
      "Training error: 0.046824478  | Accuracy: 0.9561128526645768\n",
      "Training error: 0.045563687  | Accuracy: 0.9561128526645768\n",
      "Training error: 0.04442762  | Accuracy: 0.9582027168234065\n",
      "Training error: 0.043396752  | Accuracy: 0.9582027168234065\n",
      "Training error: 0.04245568  | Accuracy: 0.9592476489028213\n",
      "Training error: 0.041591898  | Accuracy: 0.9582027168234065\n"
     ]
    }
   ],
   "source": [
    "cof = np.zeros((numClasses, DIM))\n",
    "grad_regression  = grad(regression)\n",
    "for i in range(epoch):\n",
    "    generateBatch()\n",
    "    trainError =  regression(cof)\n",
    "    acc = accuracy_score(np.argmax(regressionTest(cof), axis = 1) , y_test)\n",
    "    if i % 100 == 0:\n",
    "        print(\"Training error:\", trainError, \" | Accuracy:\",acc )\n",
    "    gradient = np.array(grad_regression(cof))\n",
    "    cof = thresholding(cof - lr * gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Performance\n",
    "\n",
    "The performance of the classification models is assessed based on classification accuracy (ACC). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of LASSO:  0.9373040752351097\n",
      "The accuracy score of Random Forest:  0.910135841170324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Junya/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/Users/Junya/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataC, label, random_state=1, test_size = 0.3)\n",
    "        \n",
    "\n",
    "clf = linear_model.SGDClassifier(loss ='log', penalty = 'l1')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"The accuracy score of LASSO: \",accuracy_score(y_test, clf.predict(X_test)))\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"The accuracy score of Random Forest: \",accuracy_score(y_test, clf.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
